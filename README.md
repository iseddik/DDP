
# Simulation of Deep Learning in a Distributed Data Parallel Scenario with PyTorch


The "Simulation of Deep Learning in a Distributed Data Parallel Scenario with PyTorch" project focuses on emulating a distributed training environment, specifically employing the Data Parallel scenario, using the PyTorch library. In this simulation, the project generates synthetic data with two features and one binary label to train a Multi-Layer Perceptron (MLP) model. The primary objectives include ensuring data privacy and accelerating the training phase through the collaborative efforts of workers updating a central model.

![Logo](https://github.com/iseddik/Simulation-of-deep-learning-in-a-distributed-case-according-to-two-scenarios-Data-architecture-/blob/main/figure.png?raw=true)






## Features

- Ensuring data privacy
- Accelerating the training


## Authors

- [@iseddik](https://github.com/iseddik)
- [@jboussouf](https://github.com/jboussouf)



## ðŸ”— Links
[![linkedin](https://img.shields.io/badge/linkedin-0A66C2?style=for-the-badge&logo=linkedin&logoColor=white)](https://www.linkedin.com/in/issamseddik/)

## Feedback

If you have any feedback, please reach out to us at issam.seddik@ump.ac.ma or jamal.boussouf@ump.as.ma

